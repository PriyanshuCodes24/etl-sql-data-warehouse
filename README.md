# ETL-SQL-Data-Warehouse  
**A Data Warehouse and Analytics Project**

---

## ğŸ“Š Overview

Welcome to the **ETL-SQL Data Warehouse** project â€” a full-stack data warehousing solution built on **SQL Server**. This project demonstrates the end-to-end pipeline of **data ingestion**, **cleaning**, **transformation**, and **analytics modeling**, following industry best practices.

Key focuses include:

- ğŸ”„ ETL workflow orchestration  
- ğŸ§± Multi-layered schema modeling (Bronze, Silver, Gold)  
- ğŸš€ Performance-aware batch processing  
- ğŸ” Auditability and traceability across all layers  

---

## ğŸ§± Architecture

The project follows a **layered medallion architecture**, designed for modularity, scalability, and analytics readiness:

- **Bronze Layer**: Raw ingestion from CSV files into SQL Server staging tables  
- **Silver Layer**: Cleaned, standardized, and enriched data with audit fields  
- **Gold Layer**: Dimensional models and fact views optimized for BI, reporting, and dashboarding  

---

## âœ… Project Highlights

### ğŸ”¹ Bronze Layer

- Six staging tables across **CRM** and **ERP** domains:
  - **CRM**: Customer Info, Product Info, Sales Details  
  - **ERP**: Customer Info, Location Info, Product Category Info  
- `bronze.load_bronze` stored procedure:
  - Performs `BULK INSERT` from CSVs  
  - Truncates and reloads data for full refresh  
  - Tracks execution time per table and batch  
  - Structured logging for transparency  

---

### ğŸ”¸ Silver Layer

- All silver tables defined with:
  - Consistent naming conventions  
  - Appropriate data types and constraints  
  - `dwh_create_date` audit columns  
- `silver.load_silver` stored procedure:
  - Truncates and reloads data  
  - Cleans and transforms input, including:
    - Trimming whitespace  
    - Standardizing codes (e.g., gender, marital status, product line)  
    - Handling `NULL`/blank values with `'n/a'`  
    - Converting integer-based dates to SQL `DATE`  
  - Built-in `TRY...CATCH` for error handling  
  - Execution time tracking per table and overall  

---

### ğŸ§ª Data Validation & Audits

- Independent audit scripts per silver table to verify:
  - Extra or trailing spaces  
  - Missing, malformed, or default values  
  - Invalid or unrecognized lookup codes  
- Scripts include:
  - Preview logic  
  - Comments for quick resolution in transformation layer  

---

### ğŸŸ¡ Gold Layer

- Dimensional and fact views ready for analytics:
  - `gold.dimension_customers`: Combines CRM & ERP customer data  
  - `gold.dimension_products`: Enriches product info with category mapping  
  - `gold.fact_sales`: Sales fact view using surrogate keys and consistent date formats  
- Features:
  - Surrogate keys via `ROW_NUMBER()`  
  - Optimized for Power BI/Tableau/Looker  
  - Grain definitions and referential integrity captured in [Gold Layer Data Catalog](docs/gold_layer_data_catalog.md)

---

## ğŸ› ï¸ Requirements

To run this project locally or in a dev environment, ensure the following are available:

| Requirement            | Details                                |
|------------------------|----------------------------------------|
| **SQL Server**         | 2019 or later                          |
| **Client Tools**       | SQL Server Management Studio (SSMS) or Azure Data Studio |
| **Data Files**         | CSV files placed in `./datasets/` directory |

---

## ğŸ“ Repository Structure

```plaintext
etl-sql-data-warehouse/
â”‚
â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ ddl_bronze.sql
â”‚   â”œâ”€â”€ procedure_loadBronze.sql
â”‚
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ ddl_silver.sql
â”‚   â”œâ”€â”€ data_quality_audit_script.sql
â”‚   â”œâ”€â”€ procedure_loadSilver.sql
â”‚
â”œâ”€â”€ gold/
â”‚   â”œâ”€â”€ ddl_loadgold.sql
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ gold_layer_data_catalog.md
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ [CSV files for CRM and ERP domains]
â”‚
â””â”€â”€ README.md
```
---

ğŸ“„ License

This project is available for educational and professional use. Attribution is appreciated but not required.

---

ğŸ™Œ Acknowledgements

This project was developed as part of a personal data engineering portfolio to showcase real-world ETL and data warehouse design patterns using SQL Server :)
